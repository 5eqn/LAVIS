datasets:
  coco_vqa:
    # data_dir: ${env.data_dir}/datasets
    data_type: images # [images|videos|features]

    build_info:
      # Be careful not to append minus sign (-) before split to avoid itemizing
      annotations:
        train:
          url:
              - https://storage.googleapis.com/sfr-vision-language-research/datasets/vqa_train.json
              - https://storage.googleapis.com/sfr-vision-language-research/datasets/vqa_val.json
          storage:
              - okvqa/annotations/vqa_train.json
              - okvqa/annotations/vqa_val.json
        test:
          url:
              - https://storage.googleapis.com/sfr-vision-language-research/datasets/vqa_test.json
              - https://storage.googleapis.com/sfr-vision-language-research/datasets/answer_list.json
          storage:
              - okvqa/annotations/vqa_test.json
              - okvqa/annotations/answer_list.json
      images:
          storage: coco/images/
        # train:
        #   # url:
        #   #     - http://images.cocodataset.org/zips/train2014.zip
        #   #     - http://images.cocodataset.org/zips/val2014.zip
        #   storage: coco/images/
        # test:
        #   # url:
        #   #     - http://images.cocodataset.org/zips/test2015.zip
        #   storage: coco/images/

model:
  arch: blip_nlvr
  pretrained: "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_nlvr.pth"
  num_classes: 2

  # vit encoder
  vit_type: "base"
  vit_grad_ckpt: False
  vit_ckpt_layer: 0
  vit_layer_norm_epsilon: 1e-6

  image_size: 384

  # bert config
  med_config_path: "configs/models/med_config.json"

preprocess:
  vis_processor:
      train:
        name: "blip_image_train"
        image_size: 384
      eval:
        name: "blip_image_eval"
        image_size: 384
  text_processor:
      train:
        name: "blip_caption"
      eval:
        name: "blip_caption"

model:
  arch: blip_caption
  from_finetuned: True

  pretrained: "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth"
  finetuned: "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth"

  vit_type: "large"
  vit_grad_ckpt: True
  vit_ckpt_layer: 5

  image_size: 384

  # bert config
  med_config_path: "configs/models/med_large_config.json"

  # generation configs
  prompt: "a picture of "


preprocess:
    vis_processor:
        train:
          name: "blip_image_train"
        eval:
          name: "blip_image_eval"
    text_processor:
        train:
          name: "blip_caption"
          prompt: "a picture of "
        eval:
          name: "blip_caption"

model:
  arch: blip_caption
  pretrained: "https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth"

  vit_type: "large"
  vit_grad_ckpt: True
  vit_ckpt_layer: 5
  batch_size: 16
  init_lr: 2e-6

  image_size: 384

  # bert config
  med_config_path: "configs/models/med_large_config.json"

  # generation configs
  prompt: "a picture of "